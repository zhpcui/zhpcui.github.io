<html>

<head>
<title>Real-Time Dense Mapping for Self-Driving Vehicles using Fisheye Cameras</title></head>

<body>

<div class=WordSection1>

<p class=MsoNormal><o:p>&nbsp;</o:p></p>

<div align=center>

<table class=MsoNormalTable border=0 cellpadding=0 width=800 style='width:600.0pt;
 mso-cellspacing:1.5pt;mso-yfti-tbllook:1184;mso-padding-alt:0cm 5.4pt 0cm 5.4pt'>
 
 <tr>
  <td>
  <p align=center style='text-align:center'>
  <b style='mso-bidi-font-weight:normal'>
  <span style='font-size:24.0pt'>Real-Time Dense Mapping for Self-Driving Vehicles using Fisheye Cameras</span></b></p>
  </td>
 </tr>
</table>

</div>

<p class=MsoNormal><o:p>&nbsp;</o:p></p>

<div align=center>

<table class=MsoNormalTable border=0 cellpadding=0 width=800 style='width:600.0pt;
 mso-cellspacing:1.5pt;mso-yfti-tbllook:1184;mso-padding-alt:0cm 5.4pt 0cm 5.4pt'
 id=Table2>
 
  <tr style='mso-yfti-irow:0;mso-yfti-firstrow:yes;mso-yfti-lastrow:yes'>
  <td ></td>
 </tr>
</table>

</div>

<p></p>

<div align=center>

<table class=MsoNormalTable border=0 cellpadding=0 width=800 style='width:600.0pt;
 mso-cellspacing:1.5pt;mso-yfti-tbllook:1184;mso-padding-alt:0cm 5.4pt 0cm 5.4pt'>
 
 <tr style='mso-fareast-font-family:"Times New Roman"' style='font-size:14.0pt'>
  <td width=803>
  <h3>Abstract:</h3>
  
  <p style="text-align: justify">We present a real-time dense geometric mapping algorithm for large-scale environments. Unlike existing methods which use pinhole cameras, our implementation is based on fisheye cameras whose large field of view benefits various computer vision applications for self-driving vehicles such as visual-inertial odometry, visual localization, and object detection. Our algorithm runs on in-vehicle PCs at approximately 15 Hz, enabling vision-only 3D scene perception for self-driving vehicles. For each synchronized set of images captured by multiple cameras, we first compute a depth map for a reference camera using plane-sweeping stereo. To maintain both accuracy and efficiency, while accounting for the fact that fisheye images have a lower geometric resolution, we recover the depths using multiple image resolutions. We adopt the fast object detection framework, YOLOv3, to remove potentially dynamic objects. At the end of the pipeline, we fuse the fisheye depth images into the truncated signed distance function (TSDF) volume to obtain a 3D map. We evaluate our method on large-scale urban datasets, and results show that our method works well in complex environments.</p>
  
  
  <h3><strong>Online Video</strong></h3>
  
  <div align=center>
  <table class=MsoNormalTable border=0 width=516>
   
   <tr>
    <td>
    <p align=center style='text-align:center'><strong>Spotlight </strong></p>    </td>
   </tr>
   
   <tr align=center style='mso-yfti-irow:1'>
    <td style='padding:.75pt .75pt .75pt .75pt'>
    <iframe width="560" height="315" src="https://www.youtube.com/embed/ILQzmnQX7DM" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>    </td>
   </tr>
  
  </table>
  
  
  </div>
  <h3><strong>Download:</strong>
  </h3>
  
  
  <p><a href="https://arxiv.org/pdf/1809.06132.pdf">"Real-Time Dense Mapping for Self-Driving Vehicles using Fisheye Cameras"</a>, Zhaopeng Cui, Lionel Heng, Ye Chuan Yeo, Andreas Geiger, Marc Pollefeys, and Torsten Sattler.
   arXiv preprint arXiv:1809.06132, 2018.</p>
  <p>&nbsp;</p></td>
 </tr>
</table>

</div>

</div>

</body>

</html>
